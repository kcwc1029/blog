{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 引入密鑰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 載入 .env 檔案\n",
    "load_dotenv()\n",
    "# 設定 OpenAI API 密鑰\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain\n",
    "- 查看使用不同model：https://python.langchain.com/docs/integrations/chat/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 初始化模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4\",  # 指定模型名稱\n",
    "    openai_api_key=api_key  # 傳入正確的 API 金鑰參數名稱\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "# 設置對話內容\n",
    "messages = [\n",
    "    SystemMessage(content=\"请你作为我的物理课助教，用通俗易懂且间接的语言帮我解释物理概念。\"),\n",
    "    HumanMessage(content=\"什么是波粒二象性？\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='想象你有一个超级能力，你可以既变成一个人，又可以变成一只鸟。当你是人的时候，你可以和别人交谈，抓东西，走路等等。当你变成鸟的时候，你就可以飞翔，鸣叫，吃虫子等等。你可以根据你的需要在人和鸟之间自由切换。\\n\\n这就是波粒二象性的描述。光（或其他粒子）就像这样的超级能力者，它有时候表现得像粒子，有时候又表现得像波动。当我们说光像粒子时，就像光能击中物体并使其发热，这就像一个人能够拿起和扔掉物体。而当我们说光像波动时，就像光能够通过水面产生波纹，这就像鸟儿在水面上飞翔留下的波纹。所以，光具有波粒二象性。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 296, 'prompt_tokens': 64, 'total_tokens': 360, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-78a2675b-5337-4d1a-871d-7a00aff695ee-0', usage_metadata={'input_tokens': 64, 'output_tokens': 296, 'total_tokens': 360, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=PromptTemplate(input_variables=['input_language', 'output_language'], input_types={}, partial_variables={}, template='您是一位專業的翻譯，能夠將{input_language}翻譯成{output_language}，並且輸出文本會根據用戶要求的任何語言風格進行調整。請只輸出翻譯後的文本，不要有任何其他內容。') additional_kwargs={}\n",
      "['input_language', 'output_language']\n",
      "\n",
      "content='您是一位專業的翻譯，能夠將英语翻譯成汉语，並且輸出文本會根據用戶要求的任何語言風格進行調整。請只輸出翻譯後的文本，不要有任何其他內容。' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "system_template_text=\"您是一位專業的翻譯，能夠將{input_language}翻譯成{output_language}，並且輸出文本會根據用戶要求的任何語言風格進行調整。請只輸出翻譯後的文本，不要有任何其他內容。\"\n",
    "system_prompt_template = SystemMessagePromptTemplate.from_template(system_template_text)\n",
    "print(system_prompt_template)\n",
    "print(system_prompt_template.input_variables)\n",
    "print()\n",
    "system_prompt = system_prompt_template.format(input_language=\"英语\", output_language=\"汉语\")\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['style', 'text']\n",
      "\n",
      "content=\"文本：I'm so hungry I could eat a horse\\n語言風格：文言文\" additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "human_template_text = \"文本：{text}\\n語言風格：{style}\"\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(human_template_text)\n",
    "print(human_prompt_template.input_variables)\n",
    "print()\n",
    "human_prompt = human_prompt_template.format(text=\"I'm so hungry I could eat a horse\", style=\"文言文\")\n",
    "print(human_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我饥若狼，几乎可食马也。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 初始化模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4\",  # 指定模型名稱\n",
    "    openai_api_key=api_key  # 傳入正確的 API 金鑰參數名稱\n",
    ")\n",
    "\n",
    "response = model.invoke([\n",
    "    system_prompt,\n",
    "    human_prompt\n",
    "])\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在prompt裡面塞小範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"格式化以下客户信息：\\n姓名 -> {customer_name}\\n年龄 -> {customer_age}\\n 城市 -> {customer_city}\"),\n",
    "        (\"ai\", \"##客户信息\\n- 客户姓名：{formatted_name}\\n- 客户年龄：{formatted_age}\\n- 客户所在地：{formatted_city}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"customer_name\": \"张三\", \n",
    "        \"customer_age\": \"27\",\n",
    "        \"customer_city\": \"长沙\",\n",
    "        \"formatted_name\": \"张三\",\n",
    "        \"formatted_age\": \"27岁\",\n",
    "        \"formatted_city\": \"湖南省长沙市\"\n",
    "    },\n",
    "    {\n",
    "        \"customer_name\": \"李四\", \n",
    "        \"customer_age\": \"42\",\n",
    "        \"customer_city\": \"广州\",\n",
    "        \"formatted_name\": \"李四\",\n",
    "        \"formatted_age\": \"42岁\",\n",
    "        \"formatted_city\": \"广东省广州市\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 組成提示句\n",
    "few_shot_template = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='格式化以下客户信息：\\n姓名 -> 张三\\n年龄 -> 27\\n 城市 -> 长沙', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='##客户信息\\n- 客户姓名：张三\\n- 客户年龄：27岁\\n- 客户所在地：湖南省长沙市', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='格式化以下客户信息：\\n姓名 -> 李四\\n年龄 -> 42\\n 城市 -> 广州', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='##客户信息\\n- 客户姓名：李四\\n- 客户年龄：42岁\\n- 客户所在地：广东省广州市', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"格式化以下客户信息：\\n姓名 -> 王五\\n年龄 -> 31\\n 城市 -> 郑州'\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 叫他依照我鑰的格式去生成\n",
    "final_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        few_shot_template,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_prompt = final_prompt_template.invoke({\"input\": \"格式化以下客户信息：\\n姓名 -> 王五\\n年龄 -> 31\\n 城市 -> 郑州'\"})\n",
    "final_prompt.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 客户信息\n",
      "- 客户姓名：王五\n",
      "- 客户年龄：31岁\n",
      "- 客户所在地：河南省郑州市\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4\",  # 指定模型名稱\n",
    "    openai_api_key=api_key  # 傳入正確的 API 金鑰參數名稱\n",
    ")\n",
    "\n",
    "response = model.invoke(final_prompt)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
