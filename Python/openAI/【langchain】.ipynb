{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "openai                *  C:\\Users\\33313\\.conda\\envs\\openai\n",
      "base                     D:\\anaconda3\n",
      "\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!conda env list\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 引入密鑰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 載入 .env 檔案\n",
    "load_dotenv()\n",
    "# 設定 OpenAI API 密鑰\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain\n",
    "- 查看使用不同model：https://python.langchain.com/docs/integrations/chat/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.6-cp310-cp310-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n",
      "  Using cached langchain_core-0.3.19-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.144-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.10.0-py3-none-any.whl.metadata (167 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting openai<2.0.0,>=1.54.0 (from langchain_openai)\n",
      "  Using cached openai-1.55.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.0-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.17.2-cp310-cp310-win_amd64.whl.metadata (68 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.15->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.11-cp310-none-win_amd64.whl.metadata (52 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.54.0->langchain_openai)\n",
      "  Using cached anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.54.0->langchain_openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.54.0->langchain_openai)\n",
      "  Downloading jiter-0.7.1-cp310-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.54.0->langchain_openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.54.0->langchain_openai)\n",
      "  Using cached tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.0-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.54.0->langchain_openai) (0.4.6)\n",
      "Using cached langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_openai-0.2.9-py3-none-any.whl (50 kB)\n",
      "Downloading aiohttp-3.11.6-cp310-cp310-win_amd64.whl (440 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached langchain_core-0.3.19-py3-none-any.whl (409 kB)\n",
      "Using cached langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Using cached langsmith-0.1.144-py3-none-any.whl (310 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Using cached openai-1.55.0-py3-none-any.whl (389 kB)\n",
      "Using cached pydantic-2.10.0-py3-none-any.whl (454 kB)\n",
      "Downloading pydantic_core-2.27.0-cp310-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 15.7 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 57.1 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 884.2/884.2 kB 38.9 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jiter-0.7.1-cp310-none-win_amd64.whl (201 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.11-cp310-none-win_amd64.whl (136 kB)\n",
      "Downloading propcache-0.2.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yarl-1.17.2-cp310-cp310-win_amd64.whl (89 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: urllib3, tqdm, tenacity, sniffio, regex, PyYAML, pydantic-core, propcache, orjson, numpy, multidict, jsonpointer, jiter, idna, h11, greenlet, frozenlist, distro, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, tiktoken, requests-toolbelt, httpx, aiohttp, openai, langsmith, langchain-core, langchain-text-splitters, langchain_openai, langchain\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.11.6 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.2.post1 async-timeout-4.0.3 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 distro-1.9.0 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 idna-3.10 jiter-0.7.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.7 langchain-core-0.3.19 langchain-text-splitters-0.3.2 langchain_openai-0.2.9 langsmith-0.1.144 multidict-6.1.0 numpy-1.26.4 openai-1.55.0 orjson-3.10.11 propcache-0.2.0 pydantic-2.10.0 pydantic-core-2.27.0 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 tiktoken-0.8.0 tqdm-4.67.0 urllib3-2.2.3 yarl-1.17.2\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall langchain langchain_openai -y\n",
    "!pip install langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 初始化模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4\",  # 指定模型名稱\n",
    "    openai_api_key=api_key  # 傳入正確的 API 金鑰參數名稱\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "# 設置對話內容\n",
    "messages = [\n",
    "    SystemMessage(content=\"请你作为我的物理课助教，用通俗易懂且间接的语言帮我解释物理概念。\"),\n",
    "    HumanMessage(content=\"什么是波粒二象性？\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='想象你有一个超级能力，你可以既变成一个人，又可以变成一只鸟。当你是人的时候，你可以和别人交谈，抓东西，走路等等。当你变成鸟的时候，你就可以飞翔，鸣叫，吃虫子等等。你可以根据你的需要在人和鸟之间自由切换。\\n\\n这就是波粒二象性的描述。光（或其他粒子）就像这样的超级能力者，它有时候表现得像粒子，有时候又表现得像波动。当我们说光像粒子时，就像光能击中物体并使其发热，这就像一个人能够拿起和扔掉物体。而当我们说光像波动时，就像光能够通过水面产生波纹，这就像鸟儿在水面上飞翔留下的波纹。所以，光具有波粒二象性。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 296, 'prompt_tokens': 64, 'total_tokens': 360, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-78a2675b-5337-4d1a-871d-7a00aff695ee-0', usage_metadata={'input_tokens': 64, 'output_tokens': 296, 'total_tokens': 360, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=PromptTemplate(input_variables=['input_language', 'output_language'], input_types={}, partial_variables={}, template='您是一位專業的翻譯，能夠將{input_language}翻譯成{output_language}，並且輸出文本會根據用戶要求的任何語言風格進行調整。請只輸出翻譯後的文本，不要有任何其他內容。') additional_kwargs={}\n",
      "['input_language', 'output_language']\n",
      "\n",
      "content='您是一位專業的翻譯，能夠將英语翻譯成汉语，並且輸出文本會根據用戶要求的任何語言風格進行調整。請只輸出翻譯後的文本，不要有任何其他內容。' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "system_template_text=\"您是一位專業的翻譯，能夠將{input_language}翻譯成{output_language}，並且輸出文本會根據用戶要求的任何語言風格進行調整。請只輸出翻譯後的文本，不要有任何其他內容。\"\n",
    "system_prompt_template = SystemMessagePromptTemplate.from_template(system_template_text)\n",
    "print(system_prompt_template)\n",
    "print(system_prompt_template.input_variables)\n",
    "print()\n",
    "system_prompt = system_prompt_template.format(input_language=\"英语\", output_language=\"汉语\")\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['style', 'text']\n",
      "\n",
      "content=\"文本：I'm so hungry I could eat a horse\\n語言風格：文言文\" additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "human_template_text = \"文本：{text}\\n語言風格：{style}\"\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(human_template_text)\n",
    "print(human_prompt_template.input_variables)\n",
    "print()\n",
    "human_prompt = human_prompt_template.format(text=\"I'm so hungry I could eat a horse\", style=\"文言文\")\n",
    "print(human_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我饥若狼，几乎可食马也。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 初始化模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4\",  # 指定模型名稱\n",
    "    openai_api_key=api_key  # 傳入正確的 API 金鑰參數名稱\n",
    ")\n",
    "\n",
    "response = model.invoke([\n",
    "    system_prompt,\n",
    "    human_prompt\n",
    "])\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在prompt裡面塞小範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"格式化以下客户信息：\\n姓名 -> {customer_name}\\n年龄 -> {customer_age}\\n 城市 -> {customer_city}\"),\n",
    "        (\"ai\", \"##客户信息\\n- 客户姓名：{formatted_name}\\n- 客户年龄：{formatted_age}\\n- 客户所在地：{formatted_city}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"customer_name\": \"张三\", \n",
    "        \"customer_age\": \"27\",\n",
    "        \"customer_city\": \"长沙\",\n",
    "        \"formatted_name\": \"张三\",\n",
    "        \"formatted_age\": \"27岁\",\n",
    "        \"formatted_city\": \"湖南省长沙市\"\n",
    "    },\n",
    "    {\n",
    "        \"customer_name\": \"李四\", \n",
    "        \"customer_age\": \"42\",\n",
    "        \"customer_city\": \"广州\",\n",
    "        \"formatted_name\": \"李四\",\n",
    "        \"formatted_age\": \"42岁\",\n",
    "        \"formatted_city\": \"广东省广州市\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 組成提示句\n",
    "few_shot_template = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='格式化以下客户信息：\\n姓名 -> 张三\\n年龄 -> 27\\n 城市 -> 长沙', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='##客户信息\\n- 客户姓名：张三\\n- 客户年龄：27岁\\n- 客户所在地：湖南省长沙市', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='格式化以下客户信息：\\n姓名 -> 李四\\n年龄 -> 42\\n 城市 -> 广州', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='##客户信息\\n- 客户姓名：李四\\n- 客户年龄：42岁\\n- 客户所在地：广东省广州市', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"格式化以下客户信息：\\n姓名 -> 王五\\n年龄 -> 31\\n 城市 -> 郑州'\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 叫他依照我鑰的格式去生成\n",
    "final_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        few_shot_template,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_prompt = final_prompt_template.invoke({\"input\": \"格式化以下客户信息：\\n姓名 -> 王五\\n年龄 -> 31\\n 城市 -> 郑州'\"})\n",
    "final_prompt.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 客户信息\n",
      "- 客户姓名：王五\n",
      "- 客户年龄：31岁\n",
      "- 客户所在地：河南省郑州市\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4\",  # 指定模型名稱\n",
    "    openai_api_key=api_key  # 傳入正確的 API 金鑰參數名稱\n",
    ")\n",
    "\n",
    "response = model.invoke(final_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output praser\n",
    "- 指令裡要求模型按照指定式輸出。\n",
    "- 解析模型書出，提取所需訊息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser # 依照逗號去做成list\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"{parser_instructions}\"),\n",
    "    (\"human\", \"列出五個{subject}色系的16禁制顏色碼\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# 做出生產器\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "parser_instructions = output_parser.get_format_instructions()\n",
    "print(parser_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt.invoke({\"subject\": \"莫蘭迪\", \"parser_instructions\": parser_instructions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#6A6051, #857F72, #B2ADA3, #CFCBC6, #E3DFD9\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4\",  # 指定模型名稱\n",
    "    openai_api_key=api_key  # 傳入正確的 API 金鑰參數名稱\n",
    ")\n",
    "\n",
    "response = model.invoke(final_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output praser -- 將訊息轉成json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pydantic\n",
    "!pip install --upgrade langchain langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class BookInfo(BaseModel):\n",
    "    book_name: str = Field(description=\"書籍名稱\", example=\"百年孤独\")\n",
    "    author_name: str = Field(description=\"書籍作者\", example=\"Gabriel García Márquez\")\n",
    "    genres: List[str] = Field(description=\"書籍tag\", example=[\"文學小說\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"book_name\": {\"description\": \"書籍名稱\", \"example\": \"百年孤独\", \"title\": \"Book Name\", \"type\": \"string\"}, \"author_name\": {\"description\": \"書籍作者\", \"example\": \"Gabriel García Márquez\", \"title\": \"Author Name\", \"type\": \"string\"}, \"genres\": {\"description\": \"書籍tag\", \"example\": [\"文學小說\"], \"items\": {\"type\": \"string\"}, \"title\": \"Genres\", \"type\": \"array\"}}, \"required\": [\"book_name\", \"author_name\", \"genres\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# 建立 PydanticOutputParser\n",
    "output_parser = PydanticOutputParser(pydantic_object=BookInfo)\n",
    "\n",
    "# 打印格式化指令\n",
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"book_name\": {\"description\": \"書籍名稱\", \"example\": \"百年孤独\", \"title\": \"Book Name\", \"type\": \"string\"}, \"author_name\": {\"description\": \"書籍作者\", \"example\": \"Gabriel García Márquez\", \"title\": \"Author Name\", \"type\": \"string\"}, \"genres\": {\"description\": \"書籍tag\", \"example\": [\"文學小說\"], \"items\": {\"type\": \"string\"}, \"title\": \"Genres\", \"type\": \"array\"}}, \"required\": [\"book_name\", \"author_name\", \"genres\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class BookInfo(BaseModel):\n",
    "    book_name: str = Field(description=\"書籍名稱\", example=\"百年孤独\")\n",
    "    author_name: str = Field(description=\"書籍作者\", example=\"Gabriel García Márquez\")\n",
    "    genres: list[str] = Field(description=\"書籍tag\", example=[\"文學小說\"])\n",
    "\n",
    "# 初始化 PydanticOutputParser\n",
    "output_parser = PydanticOutputParser(pydantic_object=BookInfo)\n",
    "\n",
    "# 打印格式化指令\n",
    "print(output_parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"book_name\": {\"description\": \"書籍名稱\", \"example\": \"百年孤独\", \"title\": \"Book Name\", \"type\": \"string\"}, \"author_name\": {\"description\": \"書籍作者\", \"example\": \"Gabriel García Márquez\", \"title\": \"Author Name\", \"type\": \"string\"}, \"genres\": {\"description\": \"書籍tag\", \"example\": [\"文學小說\"], \"items\": {\"type\": \"string\"}, \"title\": \"Genres\", \"type\": \"array\"}}, \"required\": [\"book_name\", \"author_name\", \"genres\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output_parser = PydanticOutputParser(pydantic_object=BookInfo)\n",
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"{parser_instructions} 你輸出的結果請使用中文。\"),\n",
    "    (\"human\", \"請你幫我從書籍概述中，提取書名、作者，以及書籍的體裁。書籍概述會被三個#符號包圍。\\n###{book_introduction}###\")\n",
    "])\n",
    "\n",
    "book_introduction = \"\"\"《明朝那些事兒》，作者是當年明月。2006年3月在天涯社區首次發表，2009年3月21日連載完畢，邊寫作邊集結成書出版發行，一共7本。\n",
    "《明朝那些事兒》主要講述的是從1344年到1644年這三百年間關於明朝的一些故事。以史料為基礎，以年代和具體人物為主線，並加入了小說的筆法，語言幽默風趣。對明朝十六帝和其他王公權貴和小人物的命運進行全景展示，尤其對官場政治、戰爭、帝王心術著墨最多，並加入對當時政治經濟制度、人倫道德的演繹。\n",
    "它以一種網絡語言向讀者娓娓道出三百多年關於明朝的歷史故事、人物。其中原本在歷史中陌生、模糊的歷史人物在書中一個個變得鮮活起來。《明朝那些事兒》為讀者解讀歷史中的另一面，讓歷史變成一部活生生的生活故事。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "final_prompt = prompt.invoke({\"book_introduction\": book_introduction, \n",
    "                              \"parser_instructions\": output_parser.get_format_instructions()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4\",  # 指定模型名稱\n",
    "    openai_api_key=api_key  # 傳入正確的 API 金鑰參數名稱\n",
    ")\n",
    "\n",
    "response = model.invoke(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"book_name\": \"明朝那些事兒\",\n",
      "  \"author_name\": \"當年明月\",\n",
      "  \"genres\": [\"歷史\"]\n",
      "}\n",
      "book_name='明朝那些事兒' author_name='當年明月' genres=['歷史']\n",
      "明朝那些事兒\n",
      "['歷史']\n"
     ]
    }
   ],
   "source": [
    "print(response.content)\n",
    "result = output_parser.invoke(response) # 將模型的回覆解析出來\n",
    "print(result)\n",
    "print(result.book_name)\n",
    "print(result.genres)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
