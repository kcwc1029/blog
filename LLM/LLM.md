## 安裝最小模型：llama3.2

```bash
// 使用命令拉取模型，例如 llama3.2
ollama pull llama3.2

// 驗證模型是否可用
ollama list

// 測試模型運行
ollama run llama3.2

// 提供一個簡單的輸入測試
ollama run llama3.2 --prompt "Hello, how are you?"
```

## 確認本地 ollama 是否安裝完成

-   [http://localhost:11434/](http://localhost:11434/)
